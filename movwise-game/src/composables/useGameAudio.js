// src/composables/useGameAudio.js - å®Œå…¨ç‰ˆï¼ˆã‚¨ãƒ©ãƒ¼å¯¾ç­–ï¼‰
import { ref, reactive, computed, onMounted, onUnmounted, readonly } from 'vue'
import { phonemeAudioService } from '@/services/phonemeAudioService'
import logger from '@/utils/logger'

export function useGameAudio() {
  // === ãƒªã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªçŠ¶æ…‹ ===
  const isPlaying = ref(false)
  const currentVolume = ref(1.0)
  const audioError = ref(null)
  const isInitialized = ref(false)
  const contextState = ref('disabled')

  // === éŸ³å£°èªè­˜é–¢é€£ã®çŠ¶æ…‹ ===
  const isRecording = ref(false)
  const isAnalyzing = ref(false)
  const recognitionResults = ref([])
  const lastRecognitionConfidence = ref(0)
  const speechRecognition = ref(null)
  const mediaRecorder = ref(null)
  const audioStream = ref(null)

  const supportedFeatures = reactive({
    speechSynthesis: false,
    speechRecognition: false,
    webAudio: false,
    audioContext: false,
    mediaRecorder: false
  })

  // === è¨­å®šå€¤ ===
  const soundEnabled = computed(() => true) // éŸ³å£°æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
  const vibrationEnabled = computed(() => true) // ãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯æœ‰åŠ¹
  const autoPlayEnabled = computed(() => true) // è‡ªå‹•å†ç”Ÿã¯æœ‰åŠ¹

  // === åŠ¹æœéŸ³ã®ç¨®é¡å®šç¾©ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãªã—ï¼‰ ===
  const effectSounds = {
    correct: {
      type: 'success',
      frequency: 880,
      duration: 300,
      color: '#10B981'
    },
    incorrect: {
      type: 'error',
      frequency: 220,
      duration: 500,
      color: '#EF4444'
    },
    complete: {
      type: 'celebration',
      frequency: 660,
      duration: 800,
      color: '#8B5CF6'
    },
    button: {
      type: 'interaction',
      frequency: 440,
      duration: 100,
      color: '#3B82F6'
    },
    levelUp: {
      type: 'achievement',
      frequency: 800,
      duration: 600,
      color: '#10B981'
    },
    newRecord: {
      type: 'special',
      frequency: 1000,
      duration: 1000,
      color: '#F59E0B'
    },
    countdown: {
      type: 'timer',
      frequency: 600,
      duration: 200,
      color: '#6366F1'
    },
    timeWarning: {
      type: 'warning',
      frequency: 400,
      duration: 400,
      color: '#EF4444'
    },
    gameStart: {
      type: 'start',
      frequency: 800,
      duration: 500,
      color: '#10B981'
    },
    gameEnd: {
      type: 'end',
      frequency: 500,
      duration: 700,
      color: '#6B7280'
    },
    combo: {
      type: 'combo',
      frequency: 700,
      duration: 250,
      color: '#F97316'
    },
    perfectScore: {
      type: 'perfect',
      frequency: 1200,
      duration: 1200,
      color: '#FFD700'
    }
  }

  // === ãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾© ===
  const getVibrationPattern = (effectType) => {
    try {
      const patterns = {
        correct: [50],
        incorrect: [100, 50, 100],
        complete: [200, 100, 200, 100, 200],
        levelUp: [300, 100, 100, 100, 300],
        button: [25],
        combo: [30, 30, 30],
        perfectScore: [500, 100, 200, 100, 500],
        countdown: [100],
        timeWarning: [200, 100, 200],
        gameStart: [300],
        gameEnd: [400, 200, 400],
        newRecord: [300, 100, 300, 100, 300]
      }
      return patterns[effectType] || [50]
    } catch (error) {
      logger.warn('Vibration pattern error:', error)
      return [50]
    }
  }

  // === è¦–è¦šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼‰ ===
  const playVisualFeedback = (soundType) => {
    try {
      const effect = effectSounds[soundType]
      if (!effect) {
        logger.warn('Unknown effect type:', soundType)
        return false
      }

      // èƒŒæ™¯è‰²ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
      const body = document.body
      const originalBackground = body.style.background

      body.style.background = effect.color
      setTimeout(() => {
        body.style.background = originalBackground
      }, 150)

      // ãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ã®ã¿ï¼‰
      if (vibrationEnabled.value && 'vibrate' in navigator) {
        const pattern = getVibrationPattern(soundType)
        navigator.vibrate(pattern)
      }

      logger.log(`Visual feedback: ${soundType}`)
      return true

    } catch (error) {
      logger.warn('Visual feedback error:', error)
      return false
    }
  }

  // === éŸ³å£°æ©Ÿèƒ½ã®åˆæœŸåŒ–ï¼ˆéŸ³å£°èªè­˜è¿½åŠ ï¼‰ ===
  const initializeAudio = async () => {
    try {
      if (isInitialized.value) return true

      // Speech Synthesis ã®ã‚µãƒãƒ¼ãƒˆç¢ºèª
      supportedFeatures.speechSynthesis = 'speechSynthesis' in window

      // Speech Recognition ã®ã‚µãƒãƒ¼ãƒˆç¢ºèª
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      supportedFeatures.speechRecognition = !!SpeechRecognition

      // MediaRecorder ã®ã‚µãƒãƒ¼ãƒˆç¢ºèª
      supportedFeatures.mediaRecorder = 'MediaRecorder' in window

      // Web Audio API ã®ã‚µãƒãƒ¼ãƒˆç¢ºèª
      try {
        const AudioContext = window.AudioContext || window.webkitAudioContext
        if (AudioContext) {
          supportedFeatures.webAudio = true
          supportedFeatures.audioContext = true
        }
      } catch (error) {
        logger.warn('Web Audio API not supported:', error)
        supportedFeatures.webAudio = false
        supportedFeatures.audioContext = false
      }

      // Speech Recognition ã®åˆæœŸåŒ–
      if (supportedFeatures.speechRecognition) {
        try {
          speechRecognition.value = new SpeechRecognition()
          setupSpeechRecognition()
        } catch (error) {
          logger.warn('Speech Recognition initialization failed:', error)
          supportedFeatures.speechRecognition = false
        }
      }

      isInitialized.value = true
      contextState.value = supportedFeatures.speechSynthesis ? 'ready' : 'limited'

      logger.log('Audio system initialized with speech recognition')
      logger.log('Supported features:', supportedFeatures)

      return true

    } catch (error) {
      logger.error('Audio initialization failed:', error)
      audioError.value = error.message
      return false
    }
  }

  // === ãƒ¡ã‚¤ãƒ³éŸ³å£°å†ç”Ÿé–¢æ•° ===
  const playSound = async (type, data, options = {}) => {
    try {
      if (type === 'effect') {
        return playVisualFeedback(data)
      }

      if (type === 'word') {
        return await playWord(data)
      }

      if (type === 'phoneme') {
        return await playPhoneme(data)
      }

      logger.log(`Unknown sound type: ${type} - ${data}`)
      return playVisualFeedback('button')

    } catch (error) {
      logger.error('Sound playback error:', error)
      audioError.value = error.message
      return playVisualFeedback('button')
    }
  }

  // === éŸ³ç´ å†ç”Ÿï¼ˆå®Ÿéš›ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨ï¼‰ ===
  const playPhoneme = async (phonemeObj) => {
    try {
      isPlaying.value = true
      
      // éŸ³ç´ ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–
      let phoneme = ''
      let nativeTips = ''
      
      if (typeof phonemeObj === 'string') {
        phoneme = phonemeObj
      } else if (phonemeObj?.symbol) {
        phoneme = phonemeObj.symbol.replace(/\//g, '')
        nativeTips = phonemeObj.nativeTips || ''
      } else if (phonemeObj?.ipa) {
        phoneme = phonemeObj.ipa
        nativeTips = phonemeObj.nativeTips || ''
      } else {
        logger.warn('No phoneme data provided for playback')
        isPlaying.value = false
        return playVisualFeedback('button')
      }

      logger.log('ğŸµ Playing phoneme audio file:', phoneme, '| Tips:', nativeTips)
      
      // å®Ÿéš›ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ
      await phonemeAudioService.playPhoneme(phoneme, {
        volume: currentVolume.value,
        rate: 1.0
      })
      
      isPlaying.value = false
      logger.log('âœ… Phoneme audio completed:', phoneme)
      return true

    } catch (error) {
      logger.warn('âš ï¸ Phoneme audio playback error:', error)
      isPlaying.value = false
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Speech Synthesis ã‚’ä½¿ç”¨
      return await playPhonemeWithSpeechSynthesis(phonemeObj)
    }
  }

  // === ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Speech Synthesis ä½¿ç”¨ ===
  const playPhonemeWithSpeechSynthesis = async (phonemeObj) => {
    try {
      if (!supportedFeatures.speechSynthesis) {
        logger.log('Speech synthesis not supported, using visual feedback only')
        return playVisualFeedback('button')
      }

      let phonemeText = ''
      let ipaSymbol = ''
      
      if (typeof phonemeObj === 'string') {
        phonemeText = phonemeObj
        ipaSymbol = phonemeObj
      } else if (phonemeObj?.symbol) {
        ipaSymbol = phonemeObj.symbol.replace(/\//g, '')
        phonemeText = phonemeObj.nativeText || ipaSymbol
      } else {
        phonemeText = 'unknown sound'
        ipaSymbol = 'unknown'
      }

      const optimizedText = optimizeForNativePronunciation(ipaSymbol, phonemeText)
      
      return new Promise((resolve) => {
        const utterance = new SpeechSynthesisUtterance(optimizedText)
        utterance.rate = getOptimalRateForPhoneme(ipaSymbol)
        utterance.pitch = getOptimalPitchForPhoneme(ipaSymbol) 
        utterance.volume = currentVolume.value * 0.8 // å°‘ã—å°ã•ã‚ã«
        utterance.lang = 'en-US'
        
        const voices = speechSynthesis.getVoices()
        const bestNativeVoice = selectBestNativeVoice(voices)
        
        if (bestNativeVoice) {
          utterance.voice = bestNativeVoice
          logger.log('ğŸ™ï¸ Fallback: Using speech synthesis for:', ipaSymbol)
        }

        utterance.onend = () => {
          isPlaying.value = false
          resolve(true)
        }

        utterance.onerror = (error) => {
          isPlaying.value = false
          logger.warn('Speech synthesis fallback error:', error)
          playVisualFeedback('incorrect')
          resolve(false)
        }

        speechSynthesis.speak(utterance)
      })

    } catch (error) {
      logger.warn('Speech synthesis fallback failed:', error)
      isPlaying.value = false
      return playVisualFeedback('incorrect')
    }
  }

  // === å˜èªå†ç”Ÿï¼ˆNative Pronunciation with Word-Level Optimizationï¼‰ ===
  const playWord = async (wordObj) => {
    try {
      if (!soundEnabled.value || !supportedFeatures.speechSynthesis) {
        logger.log('Word playback disabled or not supported:', wordObj?.word)
        return playVisualFeedback('button')
      }

      isPlaying.value = true
      
      const word = typeof wordObj === 'string' ? wordObj : wordObj?.word
      const pronunciation = wordObj?.pronunciation || ''
      const difficulty = wordObj?.difficulty || 'normal'
      const wordType = wordObj?.type || 'general'
      
      if (!word) {
        logger.warn('No word provided for playback')
        return playVisualFeedback('button')
      }

      // Advanced word pronunciation optimization
      const optimizedWord = optimizeWordForNativePronunciation(word, pronunciation, wordType)
      
      return new Promise((resolve) => {
        const utterance = new SpeechSynthesisUtterance(optimizedWord)
        
        // Dynamic native pronunciation settings based on word characteristics
        utterance.rate = getOptimalRateForWord(word, difficulty)
        utterance.pitch = getOptimalPitchForWord(word, wordType)
        utterance.volume = currentVolume.value
        utterance.lang = 'en-US'
        
        // Premium native voice selection with accent preference
        const voices = speechSynthesis.getVoices()
        const bestNativeVoice = selectBestNativeVoice(voices, 'american')
        
        if (bestNativeVoice) {
          utterance.voice = bestNativeVoice
          logger.log('ğŸ™ï¸ Using premium native voice for word:', bestNativeVoice.name, '| Word:', word, '| Type:', wordType)
        }

        utterance.onend = () => {
          isPlaying.value = false
          logger.log('âœ… Native word completed:', word, '| Optimized:', optimizedWord)
          resolve(true)
        }

        utterance.onerror = (error) => {
          isPlaying.value = false
          logger.warn('âš ï¸ Native word error:', error)
          playVisualFeedback('incorrect')
          resolve(false)
        }

        utterance.onstart = () => {
          logger.log('ğŸ¤ Native word started:', word)
          if (pronunciation) {
            logger.log('ğŸ”Š Pronunciation guide:', pronunciation)
          }
        }

        // ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°å†ç”Ÿé–‹å§‹
        speechSynthesis.speak(utterance)
      })

    } catch (error) {
      isPlaying.value = false
      logger.warn('Native word playback error:', error)
      return playVisualFeedback('button')
    }
  }

  // === åŠ¹æœéŸ³å†ç”Ÿï¼ˆè¦–è¦šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã¿ï¼‰ ===
  const playEffectSound = async (effectType, options = {}) => {
    try {
      logger.log('Effect sound (visual only):', effectType)
      return playVisualFeedback(effectType)
    } catch (error) {
      logger.warn('Effect sound error:', error)
      return false
    }
  }

  // === éŸ³å£°ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å†ç”Ÿ ===
  const playSequence = async (sequence, options = {}) => {
    try {
      if (!Array.isArray(sequence)) {
        logger.warn('Invalid sequence format')
        return false
      }

      for (const item of sequence) {
        if (item && item.type && item.data) {
          await playSound(item.type, item.data, { ...options, ...item.options })

          if (item.delay && typeof item.delay === 'number') {
            await new Promise(resolve => setTimeout(resolve, item.delay))
          }
        }
      }
      return true
    } catch (error) {
      logger.warn('Sequence playback error:', error)
      return false
    }
  }

  // === è‡ªå‹•å†ç”Ÿæ©Ÿèƒ½ï¼ˆç„¡åŠ¹åŒ–ï¼‰ ===
  const playAutoAudio = async (phoneme, word = null) => {
    try {
      logger.log('Auto audio disabled:', { phoneme, word })
      return false
    } catch (error) {
      logger.warn('Auto audio error:', error)
      return false
    }
  }

  // === Be Verb Rushå°‚ç”¨ï¼šã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³éŸ³å£° ===
  const playCountdown = async (number) => {
    try {
      logger.log('Countdown (visual only):', number)
      return playVisualFeedback('countdown')
    } catch (error) {
      logger.warn('Countdown failed:', error)
      return false
    }
  }

  // === Be Verb Rushå°‚ç”¨ï¼šã‚²ãƒ¼ãƒ é–‹å§‹éŸ³ ===
  const playGameStart = async () => {
    try {
      logger.log('Game start (visual only)')
      return playVisualFeedback('gameStart')
    } catch (error) {
      logger.warn('Game start failed:', error)
      return false
    }
  }

  // === Be Verb Rushå°‚ç”¨ï¼šã‚²ãƒ¼ãƒ çµ‚äº†éŸ³ ===
  const playGameEnd = async (isSuccess = true) => {
    try {
      logger.log('Game end (visual only):', isSuccess)
      const effectType = isSuccess ? 'complete' : 'gameEnd'
      return playVisualFeedback(effectType)
    } catch (error) {
      logger.warn('Game end failed:', error)
      return false
    }
  }

  // === Be Verb Rushå°‚ç”¨ï¼šã‚³ãƒ³ãƒœéŸ³ ===
  const playCombo = async (comboCount) => {
    try {
      logger.log('Combo (visual only):', comboCount)
      return playVisualFeedback('combo')
    } catch (error) {
      logger.warn('Combo failed:', error)
      return false
    }
  }

  // === Be Verb Rushå°‚ç”¨ï¼šæ™‚é–“è­¦å‘ŠéŸ³ ===
  const playTimeWarning = async () => {
    try {
      logger.log('Time warning (visual only)')
      return playVisualFeedback('timeWarning')
    } catch (error) {
      logger.warn('Time warning failed:', error)
      return false
    }
  }

  // === éŸ³é‡åˆ¶å¾¡ï¼ˆç„¡åŠ¹åŒ–ï¼‰ ===
  const setVolume = (volume) => {
    try {
      currentVolume.value = Math.max(0, Math.min(1, volume))
      logger.log('Volume set (audio disabled):', currentVolume.value)
    } catch (error) {
      logger.warn('Volume setting error:', error)
    }
  }

  const increaseVolume = (step = 0.1) => {
    setVolume(currentVolume.value + step)
  }

  const decreaseVolume = (step = 0.1) => {
    setVolume(currentVolume.value - step)
  }

  // === éŸ³å£°è¨­å®šã®åˆ‡ã‚Šæ›¿ãˆï¼ˆç„¡åŠ¹åŒ–ï¼‰ ===
  const toggleSound = () => {
    try {
      logger.log('Sound toggle (disabled for stability)')
    } catch (error) {
      logger.warn('Sound toggle error:', error)
    }
  }

  const toggleVibration = () => {
    try {
      logger.log('Vibration toggle')
      // ãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã®åˆ‡ã‚Šæ›¿ãˆã¯å®Ÿè£…å¯èƒ½
    } catch (error) {
      logger.warn('Vibration toggle error:', error)
    }
  }

  const toggleAutoPlay = () => {
    try {
      logger.log('Auto play toggle (disabled)')
    } catch (error) {
      logger.warn('Auto play toggle error:', error)
    }
  }

  // === Speech Recognition ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ===
  const setupSpeechRecognition = () => {
    if (!speechRecognition.value) return

    const recognition = speechRecognition.value
    
    // åŸºæœ¬è¨­å®š
    recognition.continuous = false
    recognition.interimResults = false
    recognition.lang = 'en-US'
    recognition.maxAlternatives = 3

    // ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    recognition.onstart = () => {
      logger.log('ğŸ¤ Speech recognition started')
      isRecording.value = true
    }

    recognition.onend = () => {
      logger.log('ğŸ¤ Speech recognition ended')
      isRecording.value = false
    }

    recognition.onresult = (event) => {
      logger.log('ğŸ¤ Speech recognition result:', event)
      
      const results = []
      for (let i = 0; i < event.results.length; i++) {
        const result = event.results[i]
        for (let j = 0; j < result.length; j++) {
          results.push({
            transcript: result[j].transcript,
            confidence: result[j].confidence,
            isFinal: result.isFinal
          })
        }
      }
      
      recognitionResults.value = results
      if (results.length > 0) {
        lastRecognitionConfidence.value = results[0].confidence
      }
    }

    recognition.onerror = (event) => {
      logger.error('ğŸ¤ Speech recognition error:', event.error)
      isRecording.value = false
      audioError.value = `Speech recognition error: ${event.error}`
    }
  }

  // === éŒ²éŸ³é–‹å§‹ ===
  const startRecording = async () => {
    try {
      if (!supportedFeatures.speechRecognition) {
        throw new Error('Speech recognition not supported')
      }

      if (isRecording.value) {
        logger.warn('Recording already in progress')
        return false
      }

      // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã®è¦æ±‚
      try {
        audioStream.value = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            sampleRate: 44100
          }
        })
      } catch (error) {
        throw new Error(`Microphone access denied: ${error.message}`)
      }

      // Speech Recognition é–‹å§‹
      recognitionResults.value = []
      lastRecognitionConfidence.value = 0
      speechRecognition.value.start()

      logger.log('ğŸ¤ Recording started')
      return true

    } catch (error) {
      logger.error('Recording start error:', error)
      audioError.value = error.message
      isRecording.value = false
      return false
    }
  }

  // === éŒ²éŸ³åœæ­¢ ===
  const stopRecording = async () => {
    try {
      if (!isRecording.value) {
        logger.warn('No recording in progress')
        return false
      }

      // Speech Recognition åœæ­¢
      if (speechRecognition.value) {
        speechRecognition.value.stop()
      }

      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢
      if (audioStream.value) {
        audioStream.value.getTracks().forEach(track => track.stop())
        audioStream.value = null
      }

      logger.log('ğŸ¤ Recording stopped')
      return true

    } catch (error) {
      logger.error('Recording stop error:', error)
      audioError.value = error.message
      return false
    }
  }

  // === éŸ³å£°åˆ†æãƒ»ç™ºéŸ³åˆ¤å®š ===
  const analyzeAudio = async (targetPhoneme, options = {}) => {
    try {
      if (!recognitionResults.value.length) {
        throw new Error('No recognition results available')
      }

      isAnalyzing.value = true

      const bestResult = recognitionResults.value[0]
      const recognizedText = bestResult.transcript.toLowerCase().trim()
      const confidence = bestResult.confidence

      logger.log('ğŸ” Analyzing pronunciation:', {
        target: targetPhoneme,
        recognized: recognizedText,
        confidence: confidence
      })

      // ç™ºéŸ³ã‚¹ã‚³ã‚¢è¨ˆç®—
      const pronunciationScore = calculatePronunciationScore(
        targetPhoneme, 
        recognizedText, 
        confidence,
        options
      )

      isAnalyzing.value = false

      return {
        recognized: recognizedText,
        confidence: confidence,
        score: pronunciationScore.score,
        accuracy: pronunciationScore.accuracy,
        clarity: pronunciationScore.clarity,
        timing: pronunciationScore.timing,
        feedback: pronunciationScore.feedback
      }

    } catch (error) {
      logger.error('Audio analysis error:', error)
      isAnalyzing.value = false
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ©ãƒ³ãƒ€ãƒ ã‚¹ã‚³ã‚¢
      return {
        recognized: 'unknown',
        confidence: 0.5,
        score: Math.random() * 40 + 60, // 60-100
        accuracy: 0.7,
        clarity: 0.6,
        timing: 0.8,
        feedback: 'Analysis failed, please try again'
      }
    }
  }

  // === ç™ºéŸ³ã‚¹ã‚³ã‚¢è¨ˆç®—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  ===
  const calculatePronunciationScore = (target, recognized, confidence, options = {}) => {
    try {
      let score = 0
      let accuracy = 0
      let clarity = confidence || 0.5
      let timing = 0.8 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
      let feedback = ''

      // åŸºæœ¬ä¸€è‡´ãƒã‚§ãƒƒã‚¯
      const targetLower = target.toLowerCase().trim()
      const recognizedLower = recognized.toLowerCase().trim()

      // å®Œå…¨ä¸€è‡´
      if (targetLower === recognizedLower) {
        accuracy = 1.0
        score = 90 + (confidence * 10)
        feedback = 'Perfect pronunciation!'
      }
      // éƒ¨åˆ†ä¸€è‡´ï¼ˆéŸ³ç´ ã®ä¸€éƒ¨ãŒå«ã¾ã‚Œã¦ã„ã‚‹ï¼‰
      else if (recognizedLower.includes(targetLower) || targetLower.includes(recognizedLower)) {
        accuracy = 0.7
        score = 70 + (confidence * 20)
        feedback = 'Good pronunciation, with minor improvements needed'
      }
      // éŸ³éŸ»çš„é¡ä¼¼æ€§ãƒã‚§ãƒƒã‚¯
      else {
        const phonemeScore = calculatePhonemeScore(targetLower, recognizedLower)
        accuracy = phonemeScore
        score = 50 + (phonemeScore * 40) + (confidence * 10)
        feedback = score >= 70 ? 'Acceptable pronunciation' : 'Please practice more'
      }

      // ä¿¡é ¼åº¦ã«ã‚ˆã‚‹èª¿æ•´
      if (confidence < 0.5) {
        score *= 0.8
        feedback += ' (low confidence - speak more clearly)'
      }

      // CVçµ„ã¿åˆã‚ã›ã®ç‰¹åˆ¥å‡¦ç†
      if (options.type === 'cv-combination') {
        score = adjustScoreForCVCombination(target, recognized, score, confidence)
      }

      return {
        score: Math.max(0, Math.min(100, score)),
        accuracy: Math.max(0, Math.min(1, accuracy)),
        clarity: Math.max(0, Math.min(1, clarity)),
        timing: Math.max(0, Math.min(1, timing)),
        feedback: feedback
      }

    } catch (error) {
      logger.error('Score calculation error:', error)
      return {
        score: 60,
        accuracy: 0.6,
        clarity: 0.5,
        timing: 0.7,
        feedback: 'Score calculation failed'
      }
    }
  }

  // === éŸ³éŸ»çš„é¡ä¼¼æ€§ã‚¹ã‚³ã‚¢è¨ˆç®— ===
  const calculatePhonemeScore = (target, recognized) => {
    try {
      // æ–‡å­—ãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼æ€§ï¼ˆLevenshteinè·é›¢ã®ç°¡æ˜“ç‰ˆï¼‰
      const maxLength = Math.max(target.length, recognized.length)
      const distance = levenshteinDistance(target, recognized)
      const similarity = 1 - (distance / maxLength)

      // éŸ³éŸ»çš„ç‰¹å¾´ã«ã‚ˆã‚‹èª¿æ•´
      const phonemeAdjustment = getPhonemeAdjustment(target, recognized)
      
      return Math.max(0, similarity + phonemeAdjustment)

    } catch (error) {
      logger.error('Phoneme score calculation error:', error)
      return 0.5
    }
  }

  // === CVçµ„ã¿åˆã‚ã›ç”¨ã‚¹ã‚³ã‚¢èª¿æ•´ ===
  const adjustScoreForCVCombination = (target, recognized, baseScore, confidence) => {
    try {
      // CVçµ„ã¿åˆã‚ã›ã®ç‰¹åˆ¥ãªè©•ä¾¡åŸºæº–
      if (target.length === 2) {
        const consonant = target[0]
        const vowel = target[1]
        
        // å­éŸ³ã¨æ¯éŸ³ã®å€‹åˆ¥ãƒã‚§ãƒƒã‚¯
        const consonantPresent = recognized.toLowerCase().includes(consonant.toLowerCase())
        const vowelPresent = recognized.toLowerCase().includes(vowel.toLowerCase())
        
        if (consonantPresent && vowelPresent) {
          return Math.min(100, baseScore + 10)
        } else if (consonantPresent || vowelPresent) {
          return Math.min(100, baseScore + 5)
        }
      }
      
      return baseScore

    } catch (error) {
      logger.error('CV combination adjustment error:', error)
      return baseScore
    }
  }

  // === Levenshteinè·é›¢è¨ˆç®— ===
  const levenshteinDistance = (str1, str2) => {
    const matrix = []
    
    for (let i = 0; i <= str2.length; i++) {
      matrix[i] = [i]
    }
    
    for (let j = 0; j <= str1.length; j++) {
      matrix[0][j] = j
    }
    
    for (let i = 1; i <= str2.length; i++) {
      for (let j = 1; j <= str1.length; j++) {
        if (str2.charAt(i - 1) === str1.charAt(j - 1)) {
          matrix[i][j] = matrix[i - 1][j - 1]
        } else {
          matrix[i][j] = Math.min(
            matrix[i - 1][j - 1] + 1,
            matrix[i][j - 1] + 1,
            matrix[i - 1][j] + 1
          )
        }
      }
    }
    
    return matrix[str2.length][str1.length]
  }

  // === éŸ³éŸ»çš„ç‰¹å¾´ã«ã‚ˆã‚‹èª¿æ•´ ===
  const getPhonemeAdjustment = (target, recognized) => {
    try {
      // æ—¥æœ¬äººå­¦ç¿’è€…ã«ã¨ã£ã¦å›°é›£ãªéŸ³ã®ç‰¹åˆ¥å‡¦ç†
      const difficultPairs = {
        'r': ['l', 'w'],
        'l': ['r', 'w'],
        'v': ['b', 'f'],
        'th': ['s', 'z', 't', 'd'],
        'f': ['p', 'h']
      }

      let adjustment = 0

      for (const [sound, alternatives] of Object.entries(difficultPairs)) {
        if (target.includes(sound)) {
          for (const alt of alternatives) {
            if (recognized.includes(alt)) {
              adjustment += 0.1 // é¡ä¼¼éŸ³ã¸ã®éƒ¨åˆ†ç‚¹
            }
          }
        }
      }

      return adjustment

    } catch (error) {
      logger.error('Phoneme adjustment error:', error)
      return 0
    }
  }

  // === éŸ³å£°ãƒ†ã‚¹ãƒˆæ©Ÿèƒ½ ===
  const testAudio = async () => {
    try {
      logger.log('Audio test with speech recognition')

      const testSequence = [
        { type: 'effect', data: 'button', options: { volume: 0.5 } },
        { type: 'effect', data: 'correct', delay: 300 },
        { type: 'effect', data: 'combo', delay: 500 },
        { type: 'effect', data: 'perfectScore', delay: 500 }
      ]

      await playSequence(testSequence)

      // éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ
      if (supportedFeatures.speechRecognition) {
        logger.log('Testing speech recognition...')
        // ãƒ†ã‚¹ãƒˆã¯å®Ÿéš›ã®éŒ²éŸ³ãªã—ã§å®Ÿè¡Œ
      }

      return true
    } catch (error) {
      logger.warn('Audio test failed:', error)
      return false
    }
  }

  // === ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’æ©Ÿèƒ½ ===
  const speakText = async (text, options = {}) => {
    try {
      if (!soundEnabled.value) {
        logger.log('Sound is disabled')
        return playVisualFeedback('speak')
      }

      if (!supportedFeatures.speechSynthesis) {
        logger.warn('Speech synthesis not supported')
        return playVisualFeedback('speak')
      }

      // æ—¢å­˜ã®éŸ³å£°ã‚’åœæ­¢
      window.speechSynthesis.cancel()
      
      const utterance = new SpeechSynthesisUtterance(text)
      
      // ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
      utterance.lang = options.lang || 'en-US'
      utterance.rate = options.rate || 1.0
      utterance.pitch = options.pitch || 1.0
      utterance.volume = options.volume || currentVolume.value
      
      // ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
      utterance.onstart = () => {
        isPlaying.value = true
        logger.log(`ğŸ”Š Speaking: "${text}"`)
      }
      
      utterance.onend = () => {
        isPlaying.value = false
        logger.log('ğŸ”Š Speech completed')
      }
      
      utterance.onerror = (event) => {
        isPlaying.value = false
        logger.error('Speech synthesis error:', event)
        audioError.value = event.error
      }
      
      // éŸ³å£°å†ç”Ÿ
      window.speechSynthesis.speak(utterance)
      
      return new Promise((resolve) => {
        utterance.onend = () => {
          isPlaying.value = false
          resolve(true)
        }
        utterance.onerror = () => {
          isPlaying.value = false
          resolve(false)
        }
      })
      
    } catch (error) {
      logger.error('speakText error:', error)
      audioError.value = error.message
      return playVisualFeedback('speak')
    }
  }

  // === éŸ³å£°åœæ­¢ ===
  const stopAudio = () => {
    try {
      speechSynthesis.cancel() // é€²è¡Œä¸­ã®éŸ³å£°ã‚’åœæ­¢
      isPlaying.value = false
      logger.log('Audio stopped')
    } catch (error) {
      logger.warn('Stop audio error:', error)
    }
  }

  // === éŸ³å£°ã‚­ãƒ¥ãƒ¼ã®ã‚¯ãƒªã‚¢ ===
  const clearAudioQueue = () => {
    try {
      logger.log('Audio queue cleared')
    } catch (error) {
      logger.warn('Clear audio queue error:', error)
    }
  }

  // === ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° ===
  const handleAudioError = (error) => {
    try {
      logger.error('Audio error:', error)
      audioError.value = error.message
      isPlaying.value = false

      // ã‚¨ãƒ©ãƒ¼é€šçŸ¥ã¨ã—ã¦è¦–è¦šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
      playVisualFeedback('incorrect')
    } catch (fallbackError) {
      logger.warn('Error handling failed:', fallbackError)
    }
  }

  // === éŸ³å£°çŠ¶æ…‹ã®å–å¾— ===
  const getAudioStatus = () => {
    try {
      return {
        isEnabled: soundEnabled.value,
        isInitialized: isInitialized.value,
        hasError: !!audioError.value,
        error: audioError.value,
        contextState: contextState.value,
        supportedFeatures: { ...supportedFeatures },
        visualFeedbackEnabled: true
      }
    } catch (error) {
      logger.warn('Get audio status error:', error)
      return {
        isEnabled: false,
        isInitialized: false,
        hasError: true,
        error: error.message,
        contextState: 'error',
        supportedFeatures: {},
        visualFeedbackEnabled: true
      }
    }
  }

  // === ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œã«ã‚ˆã‚‹éŸ³å£°æœ‰åŠ¹åŒ– ===
  const enableAudio = async () => {
    try {
      if (!supportedFeatures.speechSynthesis) {
        logger.warn('Speech synthesis not supported')
        audioError.value = 'Speech synthesis not supported'
        return false
      }

      // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãŒå¿…è¦ãªå ´åˆã®å‡¦ç†
      if (speechSynthesis.paused) {
        speechSynthesis.resume()
      }

      logger.log('Audio enabled successfully')
      audioError.value = null
      contextState.value = 'ready'
      return true
    } catch (error) {
      logger.warn('Enable audio error:', error)
      audioError.value = error.message
      return false
    }
  }

  // === éŸ³å£°ç„¡åŠ¹åŒ– ===
  const disableAudio = () => {
    try {
      logger.log('Audio disabled')
      speechSynthesis.cancel() // é€²è¡Œä¸­ã®éŸ³å£°ã‚’åœæ­¢
      stopAudio()
      contextState.value = 'disabled'
    } catch (error) {
      logger.warn('Disable audio error:', error)
    }
  }

  // === ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†é–‹ï¼ˆç„¡åŠ¹åŒ–ï¼‰ ===
  const resumeAudioContext = async () => {
    try {
      logger.log('Audio context resume (disabled)')
      return false
    } catch (error) {
      logger.warn('Audio context resume error:', error)
      return false
    }
  }

  // === ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ« ===
  onMounted(async () => {
    try {
      await initializeAudio()
      logger.log('âœ… useGameAudio mounted successfully (visual feedback mode)')
    } catch (error) {
      logger.warn('Audio mount error:', error)
      handleAudioError(error)
    }
  })

  onUnmounted(() => {
    try {
      stopAudio()
      clearAudioQueue()
      logger.log('âœ… useGameAudio unmounted successfully')
    } catch (error) {
      logger.warn('Audio unmount error:', error)
    }
  })

  // === Native Pronunciation Optimization Functions ===
  const optimizeForNativePronunciation = (ipaSymbol, originalText) => {
    // IPA symbol to optimized text mapping for better TTS pronunciation
    const nativeOptimizations = {
      // Vowels - American English specific
      'Ã¦': 'a as in cat',  // /Ã¦/ -> clearer pronunciation
      'É‘': 'ah as in father', // /É‘/ -> back vowel
      'ÊŒ': 'u as in cup',    // /ÊŒ/ -> central vowel
      'Éª': 'i as in bit',    // /Éª/ -> near-close front
      'ÊŠ': 'u as in book',   // /ÊŠ/ -> near-close back
      'É™': 'uh as in about', // /É™/ -> schwa
      'É': 'er as in butter', // /É/ -> r-colored schwa
      
      // Consonants - Problematic for Japanese learners
      'Î¸': 'th as in think', // /Î¸/ -> voiceless th
      'Ã°': 'th as in this',  // /Ã°/ -> voiced th
      'r': 'American r',        // American r sound
      'l': 'American l',        // Clear l sound
      'v': 'v as in very',      // Clear v sound
      'f': 'f as in fish',      // Clear f sound
      'Ê’': 'zh as in measure', // /Ê’/ -> voiced postalveolar
      'Êƒ': 'sh as in ship',    // /Êƒ/ -> voiceless postalveolar
      'Ê§': 'ch as in chair',   // /tÊƒ/ -> voiceless postalveolar affricate
      'Ê¤': 'j as in judge',    // /dÊ’/ -> voiced postalveolar affricate
    }
    
    return nativeOptimizations[ipaSymbol] || originalText
  }
  
  const optimizeWordForNativePronunciation = (word, pronunciation, wordType) => {
    // Word-level optimizations for better native pronunciation
    const wordOptimizations = {
      // Common problematic words for Japanese learners
      'water': 'wah-ter',
      'better': 'bet-ter', 
      'little': 'lit-tle',
      'bottle': 'bot-tle',
      'right': 'rah-ight',
      'light': 'lah-ight',
      'very': 'ver-ry',
      'river': 'riv-ver',
      'this': 'th-is',
      'that': 'th-at',
      'think': 'th-ink',
      'three': 'th-ree'
    }
    
    return wordOptimizations[word.toLowerCase()] || word
  }
  
  const getOptimalRateForPhoneme = (ipaSymbol) => {
    // Slower rate for difficult phonemes
    const difficultPhonemes = ['Î¸', 'Ã°', 'r', 'l', 'Ã¦', 'ÊŒ']
    return difficultPhonemes.includes(ipaSymbol) ? 0.5 : 0.7
  }
  
  const getOptimalPitchForPhoneme = (ipaSymbol) => {
    // Higher pitch for vowels, normal for consonants
    const vowels = ['Ã¦', 'É‘', 'ÊŒ', 'Éª', 'ÊŠ', 'É™', 'É']
    return vowels.includes(ipaSymbol) ? 1.1 : 1.0
  }
  
  const getOptimalRateForWord = (word, difficulty) => {
    const baseRate = 0.8
    const difficultyModifier = {
      'easy': 0.1,
      'normal': 0,
      'hard': -0.2,
      'expert': -0.3
    }
    return Math.max(0.4, baseRate + (difficultyModifier[difficulty] || 0))
  }
  
  const getOptimalPitchForWord = (word, wordType) => {
    const basePitch = 1.0
    const typeModifier = {
      'phoneme': 0.2,
      'sight_word': 0.1,
      'vocabulary': 0,
      'grammar': -0.1
    }
    return basePitch + (typeModifier[wordType] || 0)
  }
  
  const selectBestNativeVoice = (voices, accent = 'american') => {
    // Premium native voice selection with quality ranking
    const americanVoices = voices.filter(voice => 
      voice.lang === 'en-US' && !voice.localService
    )
    
    const qualityVoices = voices.filter(voice => 
      voice.lang === 'en-US' && 
      (voice.name.includes('Premium') || 
       voice.name.includes('Neural') ||
       voice.name.includes('Enhanced') ||
       voice.name.includes('High Quality'))
    )
    
    const systemVoices = voices.filter(voice => voice.lang === 'en-US')
    const fallbackVoices = voices.filter(voice => voice.lang.startsWith('en-'))
    
    // Priority order: Quality voices > American voices > System voices > Fallback
    return qualityVoices[0] || americanVoices[0] || systemVoices[0] || fallbackVoices[0]
  }
  
  // === Enhanced Grammar Audio Support ===
  const speakGrammarInstruction = async (instruction, grammarType = 'general') => {
    try {
      if (!soundEnabled.value || !supportedFeatures.speechSynthesis) {
        logger.log('Grammar instruction playback disabled')
        return playVisualFeedback('button')
      }
      
      const utterance = new SpeechSynthesisUtterance(instruction)
      utterance.rate = 0.7
      utterance.pitch = 1.0
      utterance.volume = currentVolume.value * 0.8 // Slightly quieter for instructions
      utterance.lang = 'en-US'
      
      const voices = speechSynthesis.getVoices()
      const instructorVoice = selectBestNativeVoice(voices)
      
      if (instructorVoice) {
        utterance.voice = instructorVoice
      }
      
      return new Promise((resolve) => {
        utterance.onend = () => resolve(true)
        utterance.onerror = () => resolve(false)
        speechSynthesis.speak(utterance)
      })
    } catch (error) {
      logger.warn('Grammar instruction error:', error)
      return false
    }
  }
  
  // === Sentence Pronunciation with Grammar Focus ===
  const speakSentence = async (sentence, grammarFocus = [], options = {}) => {
    try {
      if (!soundEnabled.value || !supportedFeatures.speechSynthesis) {
        return playVisualFeedback('button')
      }
      
      // Add emphasis markers for grammar focus areas
      let enhancedSentence = sentence
      if (grammarFocus.length > 0) {
        grammarFocus.forEach(word => {
          const regex = new RegExp(`\\b${word}\\b`, 'gi')
          enhancedSentence = enhancedSentence.replace(regex, `${word}.`)
        })
      }
      
      const utterance = new SpeechSynthesisUtterance(enhancedSentence)
      utterance.rate = options.rate || 0.8
      utterance.pitch = options.pitch || 1.0
      utterance.volume = currentVolume.value
      utterance.lang = 'en-US'
      
      const voices = speechSynthesis.getVoices()
      const nativeVoice = selectBestNativeVoice(voices)
      
      if (nativeVoice) {
        utterance.voice = nativeVoice
      }
      
      return new Promise((resolve) => {
        utterance.onend = () => {
          logger.log('âœ… Grammar sentence completed:', sentence)
          resolve(true)
        }
        utterance.onerror = () => resolve(false)
        speechSynthesis.speak(utterance)
      })
    } catch (error) {
      logger.warn('Sentence pronunciation error:', error)
      return false
    }
  }
  
  // === å…¬é–‹API ===
  return {
    // çŠ¶æ…‹
    isPlaying: readonly(isPlaying),
    currentVolume: readonly(currentVolume),
    audioError: readonly(audioError),
    supportedFeatures: readonly(supportedFeatures),
    soundEnabled,
    vibrationEnabled,
    autoPlayEnabled,

    // éŸ³å£°èªè­˜çŠ¶æ…‹
    isRecording: readonly(isRecording),
    isAnalyzing: readonly(isAnalyzing),
    recognitionResults: readonly(recognitionResults),
    lastRecognitionConfidence: readonly(lastRecognitionConfidence),

    // éŸ³å£°å†ç”Ÿï¼ˆã™ã¹ã¦è¦–è¦šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã¿ï¼‰
    playSound,
    playPhoneme,
    playWord,
    playEffectSound,
    playSequence,
    playAutoAudio,
    speakText,

    // Be Verb Rushå°‚ç”¨éŸ³å£°ï¼ˆã™ã¹ã¦è¦–è¦šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã¿ï¼‰
    playCountdown,
    playGameStart,
    playGameEnd,
    playCombo,
    playTimeWarning,

    // éŸ³å£°èªè­˜ãƒ»ç™ºéŸ³åˆ¤å®š
    startRecording,
    stopRecording,
    analyzeAudio,

    // åˆ¶å¾¡
    setVolume,
    increaseVolume,
    decreaseVolume,
    toggleSound,
    toggleVibration,
    toggleAutoPlay,
    stopAudio,
    clearAudioQueue,
    enableAudio,
    disableAudio,

    // ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚°
    testAudio,
    initializeAudio,
    getAudioStatus,

    // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    handleAudioError,

    // ãƒã‚¤ãƒ†ã‚£ãƒ–ç™ºéŸ³å°‚ç”¨æ©Ÿèƒ½
    speakGrammarInstruction,
    speakSentence,
    optimizeForNativePronunciation,
    optimizeWordForNativePronunciation,
    selectBestNativeVoice,

    // éŸ³å£°èªè­˜ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    calculatePronunciationScore,
    calculatePhonemeScore,

    // ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    resumeAudioContext,
    playVisualFeedback
  }
}